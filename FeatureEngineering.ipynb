{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Feature engineering**\n",
        "\n",
        "Feature engineering is the process of creating, transforming, or selecting features (input variables) to improve the performance of machine learning models. It's one of the most critical steps in the machine learning pipeline. Here are the most important feature engineering techniques, grouped by type:\n",
        "\n"
      ],
      "metadata": {
        "id": "PmwxZbao0p6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Creation**\n",
        "Creating new features from raw data:\n",
        "\n",
        "Interaction Features: Multiply or combine two or more features to create interaction terms.\n",
        "\n",
        "Example: area = length × width\n",
        "\n",
        "Polynomial Features: Add polynomial terms (e.g., square, cube) of numeric features.\n",
        "\n",
        "Datetime Features: Extract elements like day, month, weekday, hour from timestamps.\n",
        "\n",
        "Example: date → year, month, weekday\n",
        "\n",
        "**Text Features:**\n",
        "\n",
        "Word count, character count, average word length\n",
        "\n",
        "Presence of keywords or use of NLP embeddings (TF-IDF, Word2Vec, BERT)\n",
        "\n",
        "Aggregation Features:\n",
        "\n",
        "Use group-based statistics (mean, count, sum, etc.) within categories.\n",
        "\n",
        "Example: Mean salary per department\n",
        "\n"
      ],
      "metadata": {
        "id": "D_FC66bA0_B_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Feature Transformation**\n",
        "\n",
        "Changing the scale or distribution of features:\n",
        "\n",
        "Normalization / Min-Max Scaling: Rescales features to a 0-1 range.\n",
        "\n",
        "Standardization (Z-score): Transforms data to have zero mean and unit variance.\n",
        "\n",
        "Log/Box-Cox/Power Transformations: Helps handle skewed data.\n",
        "\n",
        "Quantile Transformation: Maps feature values to a uniform or normal distribution.\n",
        "\n",
        "Binning: Convert continuous variables into discrete bins (e.g., age groups)."
      ],
      "metadata": {
        "id": "Cux6pZJ01bH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Handling Missing Values**\n",
        "\n",
        "Dealing with NaNs or nulls:\n",
        "\n",
        "Imputation:\n",
        "\n",
        "Mean, median, mode imputation\n",
        "\n",
        "KNN or regression-based imputation\n",
        "\n",
        "Missing Indicator: Add a binary flag column indicating whether a value was missing."
      ],
      "metadata": {
        "id": "xgp6NqcG1mU_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoding Categorical Variables**\n",
        "\n",
        "Convert categories into numeric formats:\n",
        "\n",
        "Label Encoding: Assigns a unique integer to each category.\n",
        "\n",
        "One-Hot Encoding: Creates binary columns for each category.\n",
        "\n",
        "Target Encoding: Replace categories with the mean of the target variable.\n",
        "\n",
        "Frequency/Count Encoding: Encode categories with their frequency/count."
      ],
      "metadata": {
        "id": "7B95uuBV13x0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Selection**\n",
        "\n",
        "Choosing the most important features:\n",
        "\n",
        "Filter Methods: Use statistical tests (chi-square, ANOVA, correlation).\n",
        "\n",
        "Wrapper Methods: Recursive Feature Elimination (RFE), Forward/Backward selection.\n",
        "\n",
        "Embedded Methods: Feature importance from models (e.g., Lasso, Tree-based models)."
      ],
      "metadata": {
        "id": "9RMpAyvt1_je"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dimensionality Reduction**\n",
        "\n",
        "Reduce feature space while preserving variance:\n",
        "\n",
        "Principal Component Analysis (PCA)\n",
        "\n",
        "t-SNE / UMAP (for visualization)\n",
        "\n",
        "Autoencoders (neural network-based)"
      ],
      "metadata": {
        "id": "jDQ4mmLS2C1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Domain-Specific Features**\n",
        "\n",
        "Use knowledge of the problem domain:\n",
        "\n",
        "Example: In finance, use technical indicators (moving averages, RSI) for stock prediction.\n",
        "\n",
        "In health, create BMI from height and weight."
      ],
      "metadata": {
        "id": "w0uI3oDb2MNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qm08BlFr1dcs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}